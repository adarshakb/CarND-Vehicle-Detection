{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os.path\n",
    "sys.path.append('/Users/abadarinath/Applications/anaconda/envs/UdacityNanoCar/lib/python3.5/site-packages')\n",
    "import numpy as np\n",
    "import cv2\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import pickle\n",
    "from skimage.feature import hog\n",
    "import glob\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "import sklearn\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from random import shuffle\n",
    "import collections\n",
    "import time\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "CAMERA_CAL_DIRECTORY = './camera_cal/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def readImagesFromDir(dirPath,fileList=None,rgb=False,format='.jpg'):\n",
    "    if fileList == None:\n",
    "        allDirfiles = [dirPath+f for f in listdir(dirPath) if isfile(join(dirPath, f)) and f.endswith(format)]\n",
    "    else:\n",
    "        allDirfiles = fileList\n",
    "    result = []\n",
    "    for i in range(len(allDirfiles)):\n",
    "        if rgb:\n",
    "            bgr_img = cv2.imread(os.path.abspath(allDirfiles[i]))\n",
    "            b,g,r = cv2.split(bgr_img)       # get b,g,r\n",
    "            result.append(cv2.merge([r,g,b]))\n",
    "        else:\n",
    "            result.append(cv2.imread(os.path.abspath(allDirfiles[i])))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def readTrainingImages(dontLoadImg=False):\n",
    "    vehicles = glob.glob('./sample_training_images/vehicles*/**/*.png', recursive=True)\n",
    "    nonvehicles = glob.glob('./sample_training_images/non-vehicles*/**/*.png', recursive=True)\n",
    "    if dontLoadImg:\n",
    "        return (vehicles,nonvehicles)\n",
    "    vehiclesImgs = readImagesFromDir(dirPath=None, fileList=vehicles)\n",
    "    nonvehiclesImgs = readImagesFromDir(dirPath=None, fileList=nonvehicles)\n",
    "    return (vehiclesImgs,nonvehiclesImgs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def displayImages(imgArray,isGray=False):\n",
    "    plt.figure()\n",
    "    for i in range(len(imgArray)):\n",
    "        if isGray:\n",
    "            plt.imshow(imgArray[i], cmap='gray')\n",
    "            plt.show()\n",
    "        else:\n",
    "            plt.imshow(imgArray[i])\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a function that takes an image, a list of bounding boxes, \n",
    "# and optional color tuple and line thickness as inputs\n",
    "# then draws boxes in that color on the output\n",
    "\n",
    "def draw_boxes(img, bboxes, color=(0, 0, 255), thick=6):\n",
    "    # make a copy of the image\n",
    "    draw_img = np.copy(img)\n",
    "    # draw each bounding box on your image copy using cv2.rectangle()\n",
    "    # Iterate through the bounding boxes\n",
    "    for bbox in bboxes:\n",
    "        # Draw a rectangle given bbox coordinates\n",
    "        cv2.rectangle(draw_img, bbox[0], bbox[1], color, thick)\n",
    "    # return the image copy with boxes drawn\n",
    "    return draw_img # Change this line to return image copy with boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a function to compute color histogram features  \n",
    "def color_hist(img, nbins=32, bins_range=(0, 256), debug=False):\n",
    "    # Compute the histogram of the RGB channels separately\n",
    "    rhist = np.histogram(img[:,:,0], bins=nbins, range=bins_range)\n",
    "    ghist = np.histogram(img[:,:,1], bins=nbins, range=bins_range)\n",
    "    bhist = np.histogram(img[:,:,2], bins=nbins, range=bins_range)\n",
    "    # Generating bin centers\n",
    "    bin_edges = rhist[1]\n",
    "    bin_centers = (bin_edges[1:]  + bin_edges[0:len(bin_edges)-1])/2\n",
    "    # Concatenate the histograms into a single feature vector\n",
    "    hist_features = np.concatenate((rhist[0], ghist[0], bhist[0]))\n",
    "    \n",
    "    # Plot a figure with all three bar charts\n",
    "    if debug:\n",
    "        fig = plt.figure(figsize=(12,3))\n",
    "        plt.subplot(131)\n",
    "        plt.bar(bin_centers, rhist[0])\n",
    "        plt.xlim(0, 256)\n",
    "        plt.title('R Histogram')\n",
    "        plt.subplot(132)\n",
    "        plt.bar(bin_centers, ghist[0])\n",
    "        plt.xlim(0, 256)\n",
    "        plt.title('G Histogram')\n",
    "        plt.subplot(133)\n",
    "        plt.bar(bin_centers, bhist[0])\n",
    "        plt.xlim(0, 256)\n",
    "        plt.title('B Histogram')\n",
    "        fig.tight_layout()\n",
    "        plt.show()\n",
    "    # Return the individual histograms, bin_centers and feature vector\n",
    "    return rhist, ghist, bhist, bin_centers, hist_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file = open(CAMERA_CAL_DIRECTORY+\"dist_pickle.p\",'rb')\n",
    "distortion = pickle.load(file)\n",
    "file.close()\n",
    "def unDistortImage(img,debug=False):\n",
    "    global distortion\n",
    "    global file\n",
    "    dst = cv2.undistort(img, distortion['mtx'], distortion['dist'], None, distortion['mtx'])\n",
    "    if debug:\n",
    "        print(\"before image\")\n",
    "        displayImages([img])\n",
    "        print(\"undistorted image\")\n",
    "        displayImages([dst])\n",
    "    return dst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cropHorizonInImage(img,debug=False):\n",
    "    img_size = (img.shape[1], img.shape[0])\n",
    "    newImg = img[img_size[1]/2:img_size[1], 0:img_size[0]] # Crop from x, y, w, h -> 100, 200, 300, 400\n",
    "    # NOTE: its img[y: y + h, x: x + w] and *not* img[x: x + w, y: y + h]\n",
    "    if debug:\n",
    "        displayImages([newImg])\n",
    "    return newImg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a function to compute color histogram features  \n",
    "# Pass the color_space flag as 3-letter all caps string\n",
    "# like 'HSV' or 'LUV' etc.\n",
    "# KEEP IN MIND IF YOU DECIDE TO USE THIS FUNCTION LATER\n",
    "# IN YOUR PROJECT THAT IF YOU READ THE IMAGE WITH \n",
    "# cv2.imread() INSTEAD YOU START WITH BGR COLOR!\n",
    "# Define a function to compute color histogram features  \n",
    "# Pass the color_space flag as 3-letter all caps string\n",
    "# like 'HSV' or 'LUV' etc.\n",
    "def bin_spatial(img, color_space='RGB', size=(64, 64), debug=False):\n",
    "    # Convert image to new color space (if specified)\n",
    "    cmap=None\n",
    "    if color_space != 'RGB':\n",
    "        if color_space == 'HSV':\n",
    "            feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "        elif color_space == 'LUV':\n",
    "            feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2LUV)\n",
    "        elif color_space == 'HLS':\n",
    "            feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "        elif color_space == 'YUV':\n",
    "            feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2YUV)\n",
    "        elif color_space == 'YCrCb':\n",
    "            feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2YCrCb)\n",
    "    else: \n",
    "        feature_image = np.copy(img)\n",
    "    \n",
    "    # Use cv2.resize().ravel() to create the feature vector\n",
    "    features = cv2.resize(feature_image, size).ravel()\n",
    "    if debug:\n",
    "        plt.plot(features)\n",
    "        plt.show()\n",
    "    # Return the feature vector\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a function to return HOG features and visualization\n",
    "def get_hog_features(img, orient, pix_per_cell, cell_per_block, debug=False, feature_vec=True):\n",
    "    if debug:\n",
    "        features, hog_image = hog(img, orientations=orient, pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                       cells_per_block=(cell_per_block, cell_per_block), transform_sqrt=False, \n",
    "                       visualise=debug, feature_vector=feature_vec)\n",
    "    else:\n",
    "        features = hog(img, orientations=orient, pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                   cells_per_block=(cell_per_block, cell_per_block), transform_sqrt=False, \n",
    "                   visualise=debug, feature_vector=feature_vec)\n",
    "    if debug:\n",
    "        plt.imshow(hog_image, cmap='gray')\n",
    "        plt.show()\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extractFeatures(img, debug=False):\n",
    "    orgImg = img\n",
    "    grayImg = cv2.cvtColor(orgImg, cv2.COLOR_RGB2GRAY)\n",
    "    featureList = []\n",
    "    \n",
    "    rhist, ghist, bhist, bin_centers, hist_features = color_hist(orgImg,debug=False)\n",
    "    featureList.append(hist_features)\n",
    "    featureList.append(bin_spatial(img, color_space='RGB', size=(img.shape[0],img.shape[1]), debug=False))\n",
    "    featureList.append(bin_spatial(img, color_space='HSV', size=(img.shape[0],img.shape[1]), debug=False))\n",
    "#     featureList.append(bin_spatial(img, color_space='LUV', size=(img.shape[0],img.shape[1]), debug=False))\n",
    "#     featureList.append(bin_spatial(img, color_space='HLS', size=(img.shape[0],img.shape[1]), debug=False))\n",
    "#     featureList.append(bin_spatial(img, color_space='YUV', size=(img.shape[0],img.shape[1]), debug=False))\n",
    "    featureList.append(bin_spatial(img, color_space='YCrCb', size=(img.shape[0],img.shape[1]), debug=False))\n",
    "    # Define HOG parameters\n",
    "    orient = 9\n",
    "    pix_per_cell = 8\n",
    "    cell_per_block = 2\n",
    "    featureList.append(get_hog_features(img=grayImg,orient=orient,pix_per_cell=pix_per_cell,cell_per_block=cell_per_block,debug=False))\n",
    "    \n",
    "    if debug:\n",
    "        for f in featureList:\n",
    "            print(len(f))\n",
    "    \n",
    "    # Create an array stack, NOTE: StandardScaler() expects np.float64\n",
    "    X = np.concatenate((featureList)).astype(np.float64)\n",
    "    # Fit a per-column scaler\n",
    "    X_scaler = StandardScaler().fit(X)\n",
    "    # Apply the scaler to X\n",
    "    scaled_X = X_scaler.transform(X)\n",
    "    \n",
    "    if debug:\n",
    "        print(len(featureList))\n",
    "        print(len(scaled_X))\n",
    "        print(\"memory \",scaled_X.nbytes)\n",
    "        plt.plot(scaled_X)\n",
    "        plt.show()\n",
    "    return scaled_X\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['./sample_training_images/non-vehicles_smallset/notcars3/extra233_87.png'\n",
      "  '0.0']\n",
      " ['./sample_training_images/non-vehicles_smallset/notcars3/extra161_73.png'\n",
      "  '0.0']\n",
      " ['./sample_training_images/non-vehicles_smallset/notcars1/image0136.png'\n",
      "  '0.0']\n",
      " ..., \n",
      " ['./sample_training_images/non-vehicles_smallset/notcars3/extra325_154.png'\n",
      "  '0.0']\n",
      " ['./sample_training_images/vehicles_smallset/cars1/92.png' '1.0']\n",
      " ['./sample_training_images/vehicles_smallset/cars3/824.png' '1.0']]\n",
      "Total samples 2321 2321 (2321, 2)\n",
      "total training samples (2088, 2) Counter({'1.0': 1080, '0.0': 1008})\n",
      "total training samples (233, 2) Counter({'0.0': 117, '1.0': 116})\n"
     ]
    }
   ],
   "source": [
    "vehicles,nonvehicle = readTrainingImages(dontLoadImg=True)\n",
    "# Define the labels vector\n",
    "y = np.concatenate((np.ones(len(vehicles)), np.zeros(len(nonvehicle))))\n",
    "final_array = np.dstack((np.concatenate((vehicles,nonvehicle)),y))[0]\n",
    "np.random.shuffle(final_array)\n",
    "print(final_array)\n",
    "print(\"Total samples\", len(final_array), len(y),final_array.shape)\n",
    "train_samples, test_samples = train_test_split(final_array, test_size=0.1)\n",
    "tmp = train_samples.shape\n",
    "print(\"total training samples\",tmp,collections.Counter(train_samples[:,1]))\n",
    "tmp = test_samples.shape\n",
    "print(\"total training samples\",tmp,collections.Counter(test_samples[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "for train_sample in train_samples:\n",
    "    #print(batch_sample)\n",
    "    bgr_img = cv2.imread(os.path.abspath(train_sample[0]))\n",
    "    b,g,r = cv2.split(bgr_img)       # get b,g,r\n",
    "    rgb_img = cv2.merge([r,g,b])\n",
    "    featuresList = extractFeatures(rgb_img,debug=False)\n",
    "    X_train.append(featuresList)\n",
    "    y_train.append([train_sample[1]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.59 Seconds to train SVC...\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "# Use a linear SVC \n",
    "svc = LinearSVC()\n",
    "# Check the training time for the SVC\n",
    "t=time.time()\n",
    "svc.fit(X_train, y_train)\n",
    "t2 = time.time()\n",
    "print(round(t2-t, 2), 'Seconds to train SVC...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of SVC =  0.9957\n",
      "My SVC predicts:  ['1.0' '0.0' '0.0' '0.0' '1.0' '1.0' '1.0' '0.0' '1.0' '1.0']\n",
      "For these 10 labels:  [['1.0'], ['0.0'], ['0.0'], ['0.0'], ['1.0'], ['1.0'], ['1.0'], ['0.0'], ['1.0'], ['1.0']]\n",
      "0.00203 Seconds to predict 10 labels with SVC\n"
     ]
    }
   ],
   "source": [
    "X_test = []\n",
    "y_test = []\n",
    "for test_sample in test_samples:\n",
    "    #print(batch_sample)\n",
    "    bgr_img = cv2.imread(os.path.abspath(test_sample[0]))\n",
    "    b,g,r = cv2.split(bgr_img)       # get b,g,r\n",
    "    rgb_img = cv2.merge([r,g,b])\n",
    "    featuresList = extractFeatures(rgb_img,debug=False)\n",
    "    X_test.append(featuresList)\n",
    "    y_test.append([test_sample[1]])\n",
    "# Check the score of the SVC\n",
    "print('Test Accuracy of SVC = ', round(svc.score(X_test, y_test), 4))\n",
    "# Check the prediction time for a single sample\n",
    "t=time.time()\n",
    "n_predict = 10\n",
    "print('My SVC predicts: ', svc.predict(X_test[0:n_predict]))\n",
    "print('For these',n_predict, 'labels: ', y_test[0:n_predict])\n",
    "t2 = time.time()\n",
    "print(round(t2-t, 5), 'Seconds to predict', n_predict,'labels with SVC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "# save the classifier\n",
    "with open('my_dumped_classifier.pkl', 'wb') as fid:\n",
    "    pickle.dump(svc, fid)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# load it again\n",
    "with open('my_dumped_classifier.pkl', 'rb') as fid:\n",
    "    svc = pickle.load(fid)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Here is your draw_boxes function from the previous exercise\n",
    "def draw_boxes(img, bboxes, color=(0, 0, 255), thick=6):\n",
    "    # Make a copy of the image\n",
    "    imcopy = np.copy(img)\n",
    "    # Iterate through the bounding boxes\n",
    "    for bbox in bboxes:\n",
    "        # Draw a rectangle given bbox coordinates\n",
    "        cv2.rectangle(imcopy, bbox[0], bbox[1], color, thick)\n",
    "    # Return the image copy with boxes drawn\n",
    "    return imcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a function that takes an image,\n",
    "# start and stop positions in both x and y, \n",
    "# window size (x and y dimensions),  \n",
    "# and overlap fraction (for both x and y)\n",
    "def slide_window(img, x_start_stop=[None, None], y_start_stop=[None, None], \n",
    "                    xy_window=(64, 64), xy_overlap=(0.5, 0.5)):\n",
    "    # If x and/or y start/stop positions not defined, set to image size\n",
    "    if x_start_stop[0] == None:\n",
    "        x_start_stop[0] = 0\n",
    "    if x_start_stop[1] == None:\n",
    "        x_start_stop[1] = img.shape[1]\n",
    "    if y_start_stop[0] == None:\n",
    "        y_start_stop[0] = 0\n",
    "    if y_start_stop[1] == None:\n",
    "        y_start_stop[1] = img.shape[0]\n",
    "    # Compute the span of the region to be searched    \n",
    "    xspan = x_start_stop[1] - x_start_stop[0]\n",
    "    yspan = y_start_stop[1] - y_start_stop[0]\n",
    "    # Compute the number of pixels per step in x/y\n",
    "    nx_pix_per_step = np.int(xy_window[0]*(1 - xy_overlap[0]))\n",
    "    ny_pix_per_step = np.int(xy_window[1]*(1 - xy_overlap[1]))\n",
    "    # Compute the number of windows in x/y\n",
    "    nx_buffer = np.int(xy_window[0]*(xy_overlap[0]))\n",
    "    ny_buffer = np.int(xy_window[1]*(xy_overlap[1]))\n",
    "    nx_windows = np.int((xspan-nx_buffer)/nx_pix_per_step) \n",
    "    ny_windows = np.int((yspan-ny_buffer)/ny_pix_per_step) \n",
    "    # Initialize a list to append window positions to\n",
    "    window_list = []\n",
    "    # Loop through finding x and y window positions\n",
    "    # Note: you could vectorize this step, but in practice\n",
    "    # you'll be considering windows one by one with your\n",
    "    # classifier, so looping makes sense\n",
    "    for ys in range(ny_windows):\n",
    "        for xs in range(nx_windows):\n",
    "            # Calculate window position\n",
    "            startx = xs*nx_pix_per_step + x_start_stop[0]\n",
    "            endx = startx + xy_window[0]\n",
    "            starty = ys*ny_pix_per_step + y_start_stop[0]\n",
    "            endy = starty + xy_window[1]\n",
    "            # Append window position to list\n",
    "            window_list.append(((startx, starty), (endx, endy)))\n",
    "    # Return the list of windows\n",
    "    return window_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a function you will pass an image \n",
    "# and the list of windows to be searched (output of slide_windows())\n",
    "def search_windows(img, windows, clf):\n",
    "\n",
    "    #1) Create an empty list to receive positive detection windows\n",
    "    on_windows = []\n",
    "    #2) Iterate over all windows in the list\n",
    "    for window in windows:\n",
    "        #3) Extract the test window from original image\n",
    "        test_img = cv2.resize(img[window[0][1]:window[1][1], window[0][0]:window[1][0]], (64, 64))     \n",
    "        #4) Extract features for that window using single_img_features()\n",
    "        #5) Scale extracted features to be fed to classifier\n",
    "        features = extractFeatures(test_img)\n",
    "        #6) Predict using your classifier\n",
    "        prediction = clf.predict(features)\n",
    "        #7) If positive (prediction == 1) then save the window\n",
    "        if prediction == 1:\n",
    "            on_windows.append(window)\n",
    "    #8) Return windows for positive detections\n",
    "    return on_windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# def generator(inputArray, batch_size=32):\n",
    "#     num_samples = len(inputArray)\n",
    "#     while 1: # Loop forever so the generator never terminates\n",
    "#         for offset in range(0, num_samples, batch_size):\n",
    "#             batch_samples = inputArray[offset:offset+batch_size]\n",
    "#             X_train = []\n",
    "#             y_train = []\n",
    "#             for batch_sample in batch_samples:\n",
    "#                 #print(batch_sample)\n",
    "#                 bgr_img = cv2.imread(os.path.abspath(batch_sample[0]))\n",
    "#                 b,g,r = cv2.split(bgr_img)       # get b,g,r\n",
    "#                 rgb_img = cv2.merge([r,g,b])\n",
    "#                 featuresList = extractFeatures(rgb_img,debug=False)\n",
    "#                 X_train.append(featuresList)\n",
    "#                 y_train.append([batch_sample[1]])\n",
    "                \n",
    "#             #print(np.array(X_train).nbytes)\n",
    "#             yield sklearn.utils.shuffle(X_train, y_train)\n",
    "\n",
    "# # compile and train the model using the generator function\n",
    "# BATCH_SIZE=512\n",
    "# train_generator = generator(train_samples, batch_size=BATCH_SIZE)\n",
    "# classes = np.unique(y)\n",
    "# # tmpXArray,tmpYArray = next(train_generator)\n",
    "# # print(len(tmpArray[0]),len(tmpArray[1]))\n",
    "# # for i in range(len(tmpXArray)):\n",
    "# #     print(tmpXArray[i])\n",
    "# #     print(tmpYArray[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# from sklearn.linear_model import SGDClassifier\n",
    "# svc = SGDClassifier(penalty=\"l2\", alpha=0.001,n_iter=100)\n",
    "# # Check the training time for the SVC\n",
    "# t=time.time()\n",
    "# for i in range(train_samples.shape[0]//BATCH_SIZE):\n",
    "#     if i%20 == 0:\n",
    "#         print(\"training batch\",i,\" of \",train_samples.shape[0]//BATCH_SIZE)\n",
    "#     X_train,y_train = next(train_generator)\n",
    "#     svc.partial_fit(X_train,y_train,classes=classes)\n",
    "# t2 = time.time()\n",
    "# print(round(t2-t, 2), 'Seconds to train SVC...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# #lets re use the generator but not make use of it for testing set\n",
    "# test_generator = generator(train_samples, batch_size=len(test_samples))\n",
    "# X_test,y_test = next(test_generator)\n",
    "# print(len(X_test),len(y_test))\n",
    "# # Check the score of the SVC\n",
    "# print('Test Accuracy of SVC = ', round(svc.score(X_test, y_test), 4))\n",
    "# # Check the prediction time for a single sample\n",
    "# t=time.time()\n",
    "# n_predict = 10\n",
    "# print('My SVC predicts: ', svc.predict(X_test[0:n_predict]))\n",
    "# print('For these',n_predict, 'labels: ', y_test[0:n_predict])\n",
    "# t2 = time.time()\n",
    "# print(round(t2-t, 5), 'Seconds to predict', n_predict,'labels with SVC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trainingPipeline(img,debug=False):\n",
    "    if debug:\n",
    "        plt.imshow(img)\n",
    "        plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pipeline(img,debug=False):\n",
    "    orgImg = img\n",
    "    unDistortedImg = unDistortImage(orgImg,debug=False)\n",
    "    croppedImg = cropHorizonInImage(unDistortedImg,debug=False)\n",
    "    \n",
    "    windows = slide_window(croppedImg, x_start_stop=[None, None], y_start_stop=[None, None], \n",
    "                    xy_window=(96, 96), xy_overlap=(0.5, 0.5))\n",
    "\n",
    "    print(\"(96, 96)\",search_windows(croppedImg, windows, svc))               \n",
    "\n",
    "    windows = slide_window(croppedImg, x_start_stop=[None, None], y_start_stop=[None, None], \n",
    "                xy_window=(64, 64), xy_overlap=(0.5, 0.5))\n",
    "    \n",
    "    print(\"(64, 64)\",search_windows(croppedImg, windows, svc))\n",
    "    \n",
    "    windows = slide_window(croppedImg, x_start_stop=[None, None], y_start_stop=[None, None], \n",
    "            xy_window=(128, 128), xy_overlap=(0.5, 0.5))\n",
    "    \n",
    "    print(\"(128, 128)\",search_windows(croppedImg, windows, svc))\n",
    "    \n",
    "    windows = slide_window(croppedImg, x_start_stop=[None, None], y_start_stop=[None, None], \n",
    "            xy_window=(256, 256), xy_overlap=(0.5, 0.5))\n",
    "    \n",
    "    print(\"(256, 256)\",search_windows(croppedImg, windows, svc))\n",
    "    \n",
    "    windows = slide_window(croppedImg, x_start_stop=[None, None], y_start_stop=[None, None], \n",
    "            xy_window=(512, 512), xy_overlap=(0.5, 0.5))\n",
    "    \n",
    "    print(\"(512, 512)\",search_windows(croppedImg, windows, svc))\n",
    "    \n",
    "#     window_img = draw_boxes(unDistortedImg, hot_windows, color=(0, 0, 255), thick=6)                    \n",
    "\n",
    "    result = img\n",
    "    if debug:\n",
    "        print(\"Orignial image\")\n",
    "        displayImages([orgImg])\n",
    "        print(\"final result\")\n",
    "        displayImages([result])\n",
    "        print(\"********************************************************************************************************\")\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(96, 96) []\n",
      "(64, 64) []\n",
      "(128, 128) []\n",
      "(256, 256) []\n",
      "(512, 512) []\n",
      "(96, 96) []\n",
      "(64, 64) []\n",
      "(128, 128) []\n",
      "(256, 256) []\n",
      "(512, 512) []\n",
      "(96, 96) []\n",
      "(64, 64) []\n",
      "(128, 128) []\n",
      "(256, 256) []\n",
      "(512, 512) []\n",
      "(96, 96) []\n",
      "(64, 64) []\n",
      "(128, 128) []\n",
      "(256, 256) []\n",
      "(512, 512) []\n",
      "(96, 96) []\n",
      "(64, 64) []\n",
      "(128, 128) []\n",
      "(256, 256) []\n",
      "(512, 512) []\n",
      "(96, 96) []\n",
      "(64, 64) []\n",
      "(128, 128) []\n",
      "(256, 256) []\n",
      "(512, 512) []\n",
      "(96, 96) []\n",
      "(64, 64) []\n",
      "(128, 128) []\n",
      "(256, 256) []\n",
      "(512, 512) []\n",
      "(96, 96) []\n",
      "(64, 64) []\n",
      "(128, 128) []\n",
      "(256, 256) []\n",
      "(512, 512) []\n",
      "(96, 96) []\n",
      "(64, 64) []\n",
      "(128, 128) []\n",
      "(256, 256) []\n",
      "(512, 512) []\n",
      "(96, 96) []\n",
      "(64, 64) []\n",
      "(128, 128) []\n",
      "(256, 256) []\n",
      "(512, 512) []\n",
      "(96, 96) []\n",
      "(64, 64) []\n",
      "(128, 128) []\n",
      "(256, 256) []\n",
      "(512, 512) []\n",
      "(96, 96) []\n",
      "(64, 64) []\n",
      "(128, 128) []\n",
      "(256, 256) []\n",
      "(512, 512) []\n",
      "(96, 96) []\n",
      "(64, 64) []\n",
      "(128, 128) []\n",
      "(256, 256) []\n",
      "(512, 512) []\n",
      "(96, 96) []\n",
      "(64, 64) []\n",
      "(128, 128) []\n",
      "(256, 256) []\n",
      "(512, 512) []\n",
      "(96, 96) []\n",
      "(64, 64) []\n",
      "(128, 128) []\n",
      "(256, 256) []\n",
      "(512, 512) []\n",
      "(96, 96) []\n",
      "(64, 64) []\n",
      "(128, 128) []\n",
      "(256, 256) []\n",
      "(512, 512) []\n"
     ]
    }
   ],
   "source": [
    "testImgs = readImagesFromDir('./test_images/',rgb=True)\n",
    "\n",
    "for i in range(len(testImgs)):\n",
    "    img = testImgs[i]\n",
    "    result = pipeline(img, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
